<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
<TITLE>Page 47</TITLE>

<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
</HEAD>
<BODY bgcolor="#FFFFFF" vlink="blue" link="blue" >
<p style="position:absolute;top:0px;left:0px"><img src="images/azure-cognitive-services-openai0047.png" width="892px" height="1252px">
</img></p>
<p style="position:absolute;top:57px;left:96px"><span style="virtical-align:top;font-size:36px;font-family:AAAAAB+SegoeUI-Semibold;color:#161616;font-weight:bold;w_h636w_h51w_h;letter-spacing:0.44135px;">Understanding&nbsp;embeddings&nbsp;in&nbsp;Azure</span></p>
<p style="position:absolute;top:107px;left:96px"><span style="virtical-align:top;font-size:36px;font-family:AAAAAB+SegoeUI-Semibold;color:#161616;font-weight:bold;w_h266w_h51w_h;letter-spacing:0.51025px;">OpenAI&nbsp;Service</span></p>
<p style="position:absolute;top:162px;left:96px"><span style="virtical-align:top;font-size:13px;font-family:AAAAAC+SegoeUI;color:#505050;w_h142w_h21w_h;letter-spacing:0.44364px;">Article&nbsp;â€¢&nbsp;05/10/2023</span></p>
<p style="position:absolute;top:208px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h677w_h24w_h;letter-spacing:0.32957px;">An&nbsp;embedding&nbsp;is&nbsp;a&nbsp;special&nbsp;format&nbsp;of&nbsp;data&nbsp;representation&nbsp;that&nbsp;can&nbsp;be&nbsp;easily&nbsp;utilized&nbsp;by</span></p>
<p style="position:absolute;top:236px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h649w_h24w_h;letter-spacing:0.38957px;">machine&nbsp;learning&nbsp;models&nbsp;and&nbsp;algorithms.&nbsp;The&nbsp;embedding&nbsp;is&nbsp;an&nbsp;information&nbsp;dense</span></p>
<p style="position:absolute;top:266px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h682w_h24w_h;letter-spacing:0.33451px;">representation&nbsp;of&nbsp;the&nbsp;semantic&nbsp;meaning&nbsp;of&nbsp;a&nbsp;piece&nbsp;of&nbsp;text.&nbsp;Each&nbsp;embedding&nbsp;is&nbsp;a&nbsp;vector</span></p>
<p style="position:absolute;top:295px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h650w_h24w_h;letter-spacing:0.36946px;">of&nbsp;floating-point&nbsp;numbers,&nbsp;such&nbsp;that&nbsp;the&nbsp;distance&nbsp;between&nbsp;two&nbsp;embeddings&nbsp;in&nbsp;the</span></p>
<p style="position:absolute;top:323px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h668w_h24w_h;letter-spacing:0.34790px;">vector&nbsp;space&nbsp;is&nbsp;correlated&nbsp;with&nbsp;semantic&nbsp;similarity&nbsp;between&nbsp;two&nbsp;inputs&nbsp;in&nbsp;the&nbsp;original</span></p>
<p style="position:absolute;top:352px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h668w_h24w_h;letter-spacing:0.34562px;">format.&nbsp;For&nbsp;example,&nbsp;if&nbsp;two&nbsp;texts&nbsp;are&nbsp;similar,&nbsp;then&nbsp;their&nbsp;vector&nbsp;representations&nbsp;should</span></p>
<p style="position:absolute;top:380px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h117w_h24w_h;letter-spacing:0.36593px;">also&nbsp;be&nbsp;similar.</span></p>
<p style="position:absolute;top:505px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h656w_h24w_h;letter-spacing:0.35679px;">Different&nbsp;Azure&nbsp;OpenAI&nbsp;embedding&nbsp;models&nbsp;are&nbsp;specifically&nbsp;created&nbsp;to&nbsp;be&nbsp;good&nbsp;at&nbsp;a</span></p>
<p style="position:absolute;top:534px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h632w_h24w_h;letter-spacing:0.38545px;">particular&nbsp;task.&nbsp;Similarity&nbsp;embeddings&nbsp;are&nbsp;good&nbsp;at&nbsp;capturing&nbsp;semantic&nbsp;similarity</span></p>
<p style="position:absolute;top:564px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h669w_h24w_h;letter-spacing:0.36607px;">between&nbsp;two&nbsp;or&nbsp;more&nbsp;pieces&nbsp;of&nbsp;text.&nbsp;Text&nbsp;search&nbsp;embeddings&nbsp;help&nbsp;measure&nbsp;whether</span></p>
<p style="position:absolute;top:592px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h683w_h24w_h;letter-spacing:0.35077px;">long&nbsp;documents&nbsp;are&nbsp;relevant&nbsp;to&nbsp;a&nbsp;short&nbsp;query.&nbsp;Code&nbsp;search&nbsp;embeddings&nbsp;are&nbsp;useful&nbsp;for</span></p>
<p style="position:absolute;top:621px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h599w_h24w_h;letter-spacing:0.41603px;">embedding&nbsp;code&nbsp;snippets&nbsp;and&nbsp;embedding&nbsp;natural&nbsp;language&nbsp;search&nbsp;queries.</span></p>
<p style="position:absolute;top:667px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h685w_h24w_h;letter-spacing:0.36433px;">Embeddings&nbsp;make&nbsp;it&nbsp;easier&nbsp;to&nbsp;do&nbsp;machine&nbsp;learning&nbsp;on&nbsp;large&nbsp;inputs&nbsp;representing&nbsp;words</span></p>
<p style="position:absolute;top:696px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h614w_h24w_h;letter-spacing:0.33603px;">by&nbsp;capturing&nbsp;the&nbsp;semantic&nbsp;similarities&nbsp;in&nbsp;a&nbsp;vector&nbsp;space.&nbsp;Therefore,&nbsp;we&nbsp;can&nbsp;use</span></p>
<p style="position:absolute;top:726px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h661w_h24w_h;letter-spacing:0.35139px;">embeddings&nbsp;to&nbsp;determine&nbsp;if&nbsp;two&nbsp;text&nbsp;chunks&nbsp;are&nbsp;semantically&nbsp;related&nbsp;or&nbsp;similar,&nbsp;and</span></p>
<p style="position:absolute;top:754px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h277w_h24w_h;letter-spacing:0.34605px;">provide&nbsp;a&nbsp;score&nbsp;to&nbsp;assess&nbsp;similarity.</span></p>
<p style="position:absolute;top:879px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h651w_h24w_h;letter-spacing:0.38440px;">Azure&nbsp;OpenAI&nbsp;embeddings&nbsp;rely&nbsp;on&nbsp;cosine&nbsp;similarity&nbsp;to&nbsp;compute&nbsp;similarity&nbsp;between</span></p>
<p style="position:absolute;top:908px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h191w_h24w_h;letter-spacing:0.41025px;">documents&nbsp;and&nbsp;a&nbsp;query.</span></p>
<p style="position:absolute;top:954px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h651w_h24w_h;letter-spacing:0.36443px;">From&nbsp;a&nbsp;mathematic&nbsp;perspective,&nbsp;cosine&nbsp;similarity&nbsp;measures&nbsp;the&nbsp;cosine&nbsp;of&nbsp;the&nbsp;angle</span></p>
<p style="position:absolute;top:983px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h700w_h24w_h;letter-spacing:0.35726px;">between&nbsp;two&nbsp;vectors&nbsp;projected&nbsp;in&nbsp;a&nbsp;multi-dimensional&nbsp;space.&nbsp;This&nbsp;is&nbsp;beneficial&nbsp;because&nbsp;if</span></p>
<p style="position:absolute;top:1013px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h692w_h24w_h;letter-spacing:0.33269px;">two&nbsp;documents&nbsp;are&nbsp;far&nbsp;apart&nbsp;by&nbsp;Euclidean&nbsp;distance&nbsp;because&nbsp;of&nbsp;size,&nbsp;they&nbsp;could&nbsp;still&nbsp;have</span></p>
<p style="position:absolute;top:1041px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h620w_h24w_h;letter-spacing:0.35756px;">a&nbsp;smaller&nbsp;angle&nbsp;between&nbsp;them&nbsp;and&nbsp;therefore&nbsp;higher&nbsp;cosine&nbsp;similarity.&nbsp;For&nbsp;more</span></p>
<p style="position:absolute;top:1070px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#0065b3;w_h611w_h24w_h;letter-spacing:0.36373px;">information&nbsp;about&nbsp;cosine&nbsp;similarity&nbsp;equations,&nbsp;see&nbsp;<a href="https://en.wikipedia.org/wiki/Cosine_similarity"style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#0065b3;w_h0w_h0w_h;letter-spacing:0.00000px;">this&nbsp;article&nbsp;on&nbsp;Wikipedia&nbsp;.</a></span></p>
<p style="position:absolute;top:1116px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h645w_h24w_h;letter-spacing:0.35067px;">An&nbsp;alternative&nbsp;method&nbsp;of&nbsp;identifying&nbsp;similar&nbsp;documents&nbsp;is&nbsp;to&nbsp;count&nbsp;the&nbsp;number&nbsp;of</span></p>
<p style="position:absolute;top:1145px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h701w_h24w_h;letter-spacing:0.40157px;">common&nbsp;words&nbsp;between&nbsp;documents.&nbsp;Unfortunately,&nbsp;this&nbsp;approach&nbsp;doesn't&nbsp;scale&nbsp;since&nbsp;an</span></p>
<p style="position:absolute;top:1175px;left:96px"><span style="virtical-align:top;font-size:16px;font-family:AAAAAC+SegoeUI;color:#161616;w_h657w_h24w_h;letter-spacing:0.33273px;">expansion&nbsp;in&nbsp;document&nbsp;size&nbsp;is&nbsp;likely&nbsp;to&nbsp;lead&nbsp;to&nbsp;a&nbsp;greater&nbsp;number&nbsp;of&nbsp;common&nbsp;words</span></p>
<p style="position:absolute;top:442px;left:96px"><span style="virtical-align:top;font-size:30px;font-family:AAAAAB+SegoeUI-Semibold;color:#161616;font-weight:bold;w_h285w_h43w_h;letter-spacing:0.59159px;">Embedding&nbsp;models</span></p>
<p style="position:absolute;top:816px;left:96px"><span style="virtical-align:top;font-size:30px;font-family:AAAAAB+SegoeUI-Semibold;color:#161616;font-weight:bold;w_h241w_h43w_h;letter-spacing:0.47556px;">Cosine&nbsp;similarity</span></p>
</BODY>
</HTML>
